{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Water Bathymetric Particle Filter Experiment\n",
    "\n",
    "This notebook runs the experiment testing the capabilities of the particle filter to conduct navigation using deep water bathymetry and for long duration.\n",
    "\n",
    "## Data set preparation\n",
    "\n",
    "First need to process the .m77t files in `source_data` into our database format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_managment import m77t as tbx\n",
    "from src.data_managment import dbmgr\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tbx.read_m77t('./test/test_data.m77t')\n",
    "data = tbx.m77t_to_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = tbx.create_trajectory(data)\n",
    "dt = ins.index.to_series().diff().dt.total_seconds().fillna(0)\n",
    "pds = tbx.find_periods((dt > 60).to_list())\n",
    "trajs = tbx.split_dataset(ins, pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath:str = os.path.join('.db')\n",
    "filename:str = 'sources.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db: dbmgr.DatabaseManager = dbmgr.DatabaseManager(source=os.path.join(filepath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trajectory_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>alt</th>\n",
       "      <th>roll</th>\n",
       "      <th>pitch</th>\n",
       "      <th>heading</th>\n",
       "      <th>speed</th>\n",
       "      <th>...</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag_tot</th>\n",
       "      <th>mag_res</th>\n",
       "      <th>gra_obs</th>\n",
       "      <th>freeair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 04:07:00</td>\n",
       "      <td>37.50166</td>\n",
       "      <td>-74.21333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.529557</td>\n",
       "      <td>7.976108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.077385</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>-9.797804</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 04:08:00</td>\n",
       "      <td>37.50333</td>\n",
       "      <td>-74.20833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.529557</td>\n",
       "      <td>7.975956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.002025</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>-9.798631</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 04:09:00</td>\n",
       "      <td>37.50500</td>\n",
       "      <td>-74.20333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.502320</td>\n",
       "      <td>5.782016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>-0.071878</td>\n",
       "      <td>-0.044040</td>\n",
       "      <td>-9.798865</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 04:10:00</td>\n",
       "      <td>37.50666</td>\n",
       "      <td>-74.20000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.529556</td>\n",
       "      <td>7.975654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.074653</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>-9.798882</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 04:11:00</td>\n",
       "      <td>37.50833</td>\n",
       "      <td>-74.19500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.334659</td>\n",
       "      <td>9.597610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>0.042095</td>\n",
       "      <td>-0.107682</td>\n",
       "      <td>-9.798489</td>\n",
       "      <td>970.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>1189</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 23:55:00</td>\n",
       "      <td>39.63000</td>\n",
       "      <td>-68.64333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.632584</td>\n",
       "      <td>7.771435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.002576</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>-9.800258</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>1190</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 23:56:00</td>\n",
       "      <td>39.63166</td>\n",
       "      <td>-68.63833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.364493</td>\n",
       "      <td>5.671705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>-0.039700</td>\n",
       "      <td>-9.800893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>1191</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 23:57:00</td>\n",
       "      <td>39.63333</td>\n",
       "      <td>-68.63500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.529425</td>\n",
       "      <td>7.778474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.098817</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>-9.800674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>1192</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 23:58:00</td>\n",
       "      <td>39.63500</td>\n",
       "      <td>-68.63000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.570684</td>\n",
       "      <td>5.673408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>-0.082570</td>\n",
       "      <td>-0.041107</td>\n",
       "      <td>-9.800555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>1193</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-04-26 23:59:00</td>\n",
       "      <td>39.63666</td>\n",
       "      <td>-68.62666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.149726</td>\n",
       "      <td>6.701595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.024195</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>-9.801006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1193 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  trajectory_id           timestamp       lat       lon  alt  roll  \\\n",
       "0        1              1 1973-04-26 04:07:00  37.50166 -74.21333  0.0   0.0   \n",
       "1        2              1 1973-04-26 04:08:00  37.50333 -74.20833  0.0   0.0   \n",
       "2        3              1 1973-04-26 04:09:00  37.50500 -74.20333  0.0   0.0   \n",
       "3        4              1 1973-04-26 04:10:00  37.50666 -74.20000  0.0   0.0   \n",
       "4        5              1 1973-04-26 04:11:00  37.50833 -74.19500  0.0   0.0   \n",
       "...    ...            ...                 ...       ...       ...  ...   ...   \n",
       "1188  1189              1 1973-04-26 23:55:00  39.63000 -68.64333  0.0   0.0   \n",
       "1189  1190              1 1973-04-26 23:56:00  39.63166 -68.63833  0.0   0.0   \n",
       "1190  1191              1 1973-04-26 23:57:00  39.63333 -68.63500  0.0   0.0   \n",
       "1191  1192              1 1973-04-26 23:58:00  39.63500 -68.63000  0.0   0.0   \n",
       "1192  1193              1 1973-04-26 23:59:00  39.63666 -68.62666  0.0   0.0   \n",
       "\n",
       "      pitch    heading     speed  ...    gyro_y    gyro_z   accel_x   accel_y  \\\n",
       "0       0.0  71.529557  7.976108  ... -0.000056 -0.000045  0.077385  0.031718   \n",
       "1       0.0  71.529557  7.975956  ... -0.000055 -0.002025 -0.000056 -0.000715   \n",
       "2       0.0  63.502320  5.782016  ... -0.000056  0.000869 -0.071878 -0.044040   \n",
       "3       0.0  71.529556  7.975654  ... -0.000052 -0.001720  0.074653  0.055329   \n",
       "4       0.0  56.334659  9.597610  ... -0.000055 -0.000513  0.042095 -0.107682   \n",
       "...     ...        ...       ...  ...       ...       ...       ...       ...   \n",
       "1188    0.0  71.632584  7.771435  ... -0.000054 -0.002576  0.001492  0.000178   \n",
       "1189    0.0  63.364493  5.671705  ... -0.000053  0.000495 -0.076904 -0.039700   \n",
       "1190    0.0  71.529425  7.778474  ... -0.000053  0.000222  0.098817  0.032400   \n",
       "1191    0.0  63.570684  5.673408  ... -0.000053 -0.001485 -0.082570 -0.041107   \n",
       "1192    0.0  68.149726  6.701595  ... -0.000053  0.002486  0.024195  0.008711   \n",
       "\n",
       "       accel_z   depth  mag_tot mag_res gra_obs freeair  \n",
       "0    -9.797804  1157.0     None    None    None    None  \n",
       "1    -9.798631  1148.0     None    None    None    None  \n",
       "2    -9.798865  1144.0     None    None    None    None  \n",
       "3    -9.798882  1146.0     None    None    None    None  \n",
       "4    -9.798489   970.0     None    None    None    None  \n",
       "...        ...     ...      ...     ...     ...     ...  \n",
       "1188 -9.800258  2610.0     None    None    None    None  \n",
       "1189 -9.800893     NaN     None    None    None    None  \n",
       "1190 -9.800674     NaN     None    None    None    None  \n",
       "1191 -9.800555     NaN     None    None    None    None  \n",
       "1192 -9.801006     NaN     None    None    None    None  \n",
       "\n",
       "[1193 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_trajectory(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag_tot</th>\n",
       "      <th>mag_res</th>\n",
       "      <th>gra_obs</th>\n",
       "      <th>freeair</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-04-26 04:07:00</td>\n",
       "      <td>1973-04-26 23:59:00</td>\n",
       "      <td>71520.0</td>\n",
       "      <td>546951.474873</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-04-27 00:02:00</td>\n",
       "      <td>1973-04-27 18:00:00</td>\n",
       "      <td>64680.0</td>\n",
       "      <td>305287.821952</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-04-27 22:14:00</td>\n",
       "      <td>1973-04-27 23:59:00</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>28708.583342</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-04-28 00:02:00</td>\n",
       "      <td>1973-04-28 01:00:00</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>15966.057413</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-04-28 05:21:00</td>\n",
       "      <td>1973-04-28 23:59:00</td>\n",
       "      <td>67080.0</td>\n",
       "      <td>386457.132840</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-07-04 15:46:00</td>\n",
       "      <td>1973-07-04 23:59:00</td>\n",
       "      <td>29580.0</td>\n",
       "      <td>151889.918467</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-07-05 00:02:00</td>\n",
       "      <td>1973-07-05 23:59:00</td>\n",
       "      <td>86220.0</td>\n",
       "      <td>462348.415355</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-07-06 00:02:00</td>\n",
       "      <td>1973-07-06 21:16:00</td>\n",
       "      <td>76440.0</td>\n",
       "      <td>399897.222517</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-07-06 22:11:00</td>\n",
       "      <td>1973-07-06 23:59:00</td>\n",
       "      <td>6480.0</td>\n",
       "      <td>31866.874649</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>test_data</td>\n",
       "      <td>1973-07-07 00:02:00</td>\n",
       "      <td>1973-07-07 21:42:00</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>378280.921723</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     source               start                stop  duration  \\\n",
       "0      1  test_data 1973-04-26 04:07:00 1973-04-26 23:59:00   71520.0   \n",
       "1      2  test_data 1973-04-27 00:02:00 1973-04-27 18:00:00   64680.0   \n",
       "2      3  test_data 1973-04-27 22:14:00 1973-04-27 23:59:00    6300.0   \n",
       "3      4  test_data 1973-04-28 00:02:00 1973-04-28 01:00:00    3480.0   \n",
       "4      5  test_data 1973-04-28 05:21:00 1973-04-28 23:59:00   67080.0   \n",
       "..   ...        ...                 ...                 ...       ...   \n",
       "103  104  test_data 1973-07-04 15:46:00 1973-07-04 23:59:00   29580.0   \n",
       "104  105  test_data 1973-07-05 00:02:00 1973-07-05 23:59:00   86220.0   \n",
       "105  106  test_data 1973-07-06 00:02:00 1973-07-06 21:16:00   76440.0   \n",
       "106  107  test_data 1973-07-06 22:11:00 1973-07-06 23:59:00    6480.0   \n",
       "107  108  test_data 1973-07-07 00:02:00 1973-07-07 21:42:00   78000.0   \n",
       "\n",
       "          distance  depth  mag_tot  mag_res  gra_obs  freeair  points  \n",
       "0    546951.474873   True    False    False    False    False    1193  \n",
       "1    305287.821952   True    False    False    False    False    1079  \n",
       "2     28708.583342   True    False    False    False    False     106  \n",
       "3     15966.057413   True    False    False    False    False      59  \n",
       "4    386457.132840   True    False    False    False    False    1119  \n",
       "..             ...    ...      ...      ...      ...      ...     ...  \n",
       "103  151889.918467   True     True     True    False    False     494  \n",
       "104  462348.415355   True     True     True    False    False    1438  \n",
       "105  399897.222517   True     True     True    False    False    1275  \n",
       "106   31866.874649   True     True     True    False    False     109  \n",
       "107  378280.921723   True     True     True    False    False    1301  \n",
       "\n",
       "[108 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_all_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'path', 'to', 'my']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"/path/to/my/file.m77t\"\n",
    "s.split(\"/\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split(s)[1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess tracklines into sql/df format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and see if the .db directory exists\n",
    "if not os.path.exists(\".db\"):\n",
    "    os.mkdir(\".db\")\n",
    "\n",
    "# Check to see if the database exists\n",
    "if not os.path.exists(\".db/tracklines.db\"):\n",
    "    tables = []\n",
    "else:\n",
    "    tables = db.get_tables(\".db/tracklines.db\")\n",
    "\n",
    "source_data_location = \"./source_data/\"\n",
    "# walk through the .m77t files in the source_data directory\n",
    "for root, dirs, files in os.walk(source_data_location):\n",
    "    for file in files:\n",
    "        if file.endswith(\".m77t\"):\n",
    "            # check to see if the file has already been processed\n",
    "            filename = os.path.splitext(file)[0]\n",
    "            if filename not in tables:\n",
    "                print(\"Processing file: \" + file)\n",
    "                data = pd.read_csv(os.path.join(root, file), delimiter=\"\\t\", header=0)\n",
    "                data = tbx.m77t_to_df(data)\n",
    "                # data.to_sql(\n",
    "                #    filename, sqlite3.connect(\".db/tracklines.db\"), if_exists=\"replace\"\n",
    "                # )\n",
    "                tbx.save_dataset(\n",
    "                    [data],\n",
    "                    [filename],\n",
    "                    output_location=\".db\",\n",
    "                    output_format=\"db\",\n",
    "                    dataset_name=\"tracklines\",\n",
    "                )\n",
    "            else:\n",
    "                print(\"Skipping file: \" + file + \" (already processed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the raw data into tracklines of continuous data collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 10  # minutes\n",
    "max_delta_t = 2  # minutes between points\n",
    "min_duration = 60  # minutes, minimum duration for a useful trackline\n",
    "\n",
    "data, names = pdset.parse_tracklines_from_db(\n",
    "    \".db/tracklines.db\",\n",
    "    # max_time,\n",
    "    # max_delta_t,\n",
    "    # min_duration,\n",
    "    data_types=[\n",
    "        \"bathy\",\n",
    "        \"mag\",\n",
    "        \"grav\",\n",
    "        [\"bathy\", \"mag\"],\n",
    "        [\"bathy\", \"grav\"],\n",
    "        [\"grav\", \"mag\"],\n",
    "        [\"bathy\", \"grav\", \"mag\"],\n",
    "    ],\n",
    ")\n",
    "# Save the parsed data to the database\n",
    "pdset.save_dataset(data, names, output_location=\".db\", output_format=\"db\", dataset_name=\"parsed\")\n",
    "# summary = pdset.get_parsed_data_summary(data, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation parameters verification\n",
    "\n",
    "First we need to tune the particle filter propagation noise to be similar to that of a marine-grade inertial navigation system. A low-end marine-grade INS should have a drift of 1 nm per 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.particle_filter import rmse, propagate\n",
    "import numpy as np\n",
    "\n",
    "time = 24 * 60  # minutes\n",
    "noise = np.array([0, 2.6, 0])\n",
    "bound = 1852  # meters\n",
    "\n",
    "errors = []\n",
    "for v in range(1, 26):\n",
    "    P = np.asarray([[0, 0, 0, 0, v, 0]])\n",
    "    T = P.copy()\n",
    "    t = 0\n",
    "    for i in range(50000):\n",
    "        # Eastward\n",
    "        u = [0, v, 0]\n",
    "        while t < time:\n",
    "            P = propagate(P, u, noise=np.diag(noise), noise_calibration_mode=True)\n",
    "            T = propagate(T, u, noise=np.diag([0, 0, 0]), noise_calibration_mode=False)\n",
    "            t += 1\n",
    "        errors.append(rmse(P, T[0, :2]))\n",
    "        # Northward\n",
    "        u = [v, 0, 0]\n",
    "        while t < time:\n",
    "            P = propagate(P, u, noise=np.diag(noise), noise_calibration_mode=True)\n",
    "            T = propagate(T, u, noise=np.diag([0, 0, 0]), noise_calibration_mode=False)\n",
    "            t += 1\n",
    "        errors.append(rmse(P, T[0, :2]))\n",
    "        # Northeastward\n",
    "        u = np.array([1, 1, 0]) / np.linalg.norm([1, 1, 0])\n",
    "        u *= v\n",
    "        while t < time:\n",
    "            P = propagate(P, u, noise=np.diag(noise), noise_calibration_mode=True)\n",
    "            T = propagate(T, u, noise=np.diag([0, 0, 0]), noise_calibration_mode=False)\n",
    "            t += 1\n",
    "        errors.append(rmse(P, T[0, :2]))\n",
    "\n",
    "print(f\"RMSE: {np.mean(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "if not os.path.exists(\".db/plots\"):\n",
    "    os.makedirs(\".db/plots\")\n",
    "\n",
    "plt.hist(errors, bins=15, density=True)\n",
    "plt.xlabel(\"RMSE (m)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"RMSE of Particle Filter\")\n",
    "plt.savefig(\".db/plots/propagation_tuning.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"velocity_noise\": [noise[1], noise[1], 0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop measurement model\n",
    "\n",
    "Next we need to develop the measurement value standard deviation. We'll first do some general examination of the data. Namely, investigating the sensor measurements to see if we can build a reasonable sensor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gmt_tool import inflate_bounds, get_map_section, get_map_point\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "if os.path.exists(\"config.json\"):\n",
    "    config = json.load(open(\"config.json\", \"r\"))\n",
    "\n",
    "tables = pdset.get_tables(\".db/parsed.db\")\n",
    "bathy_tables = [table for table in tables if \"_D_\" in table]\n",
    "\n",
    "d_bathy = np.array([])\n",
    "\n",
    "for table in bathy_tables:\n",
    "    data = pdset.table_to_df(\".db/parsed.db\", table)\n",
    "    min_lon = data.LON.min()\n",
    "    max_lon = data.LON.max()\n",
    "    min_lat = data.LAT.min()\n",
    "    max_lat = data.LAT.max()\n",
    "    min_lon, min_lat, max_lon, max_lat = inflate_bounds(min_lon, min_lat, max_lon, max_lat, 0.25)\n",
    "    bathy_map = get_map_section(min_lon, max_lon, min_lat, max_lat, \"relief\", \"15s\", \"temp\")\n",
    "    d_bathy = np.hstack([d_bathy, data[\"DEPTH\"] - (-get_map_point(bathy_map, data.LON, data.LAT))])\n",
    "\n",
    "config[\"bathy_mean_d\"] = np.mean(d_bathy, where=~np.isnan(d_bathy))\n",
    "config[\"bathy_std\"] = np.std(d_bathy, where=~np.isnan(d_bathy))\n",
    "\n",
    "if os.path.exists(\"config.json\"):\n",
    "    # delete the file\n",
    "    os.remove(\"config.json\")\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d_bathy, bins=200, density=True)\n",
    "plt.xlim([-300, 300])\n",
    "plt.xlabel(\"Depth Difference (m)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Bathymetry Difference\")\n",
    "plt.savefig(\".db/plots/bathy_diff.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate with velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.particle_filter import (\n",
    "    process_particle_filter,\n",
    "    populate_velocities,\n",
    "    plot_error,\n",
    "    plot_estimate,\n",
    "    summarize_results,\n",
    ")\n",
    "import json\n",
    "import src.process_dataset as pdset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pdset.get_tables(\".db/parsed.db\")\n",
    "bathy_tables = [table for table in tables if \"_D_\" in table]\n",
    "config = json.load(open(\"config.json\", \"r\"))\n",
    "config[\"n\"] = 1000\n",
    "config[\"cov\"] = [\n",
    "    1 / 60,\n",
    "    1 / 60,\n",
    "    0,\n",
    "    config[\"velocity_noise\"][0],\n",
    "    config[\"velocity_noise\"][1],\n",
    "    0,\n",
    "]\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdset.table_to_df(\".db/parsed.db\", bathy_tables[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\".db/plots2/estimate/\"):\n",
    "    os.makedirs(\".db/plots2/estimate/\")\n",
    "\n",
    "if not os.path.exists(\".db/plots2/errors/\"):\n",
    "    os.makedirs(\".db/plots2/errors/\")\n",
    "\n",
    "summary = None\n",
    "annotations = {\"recovery\": 1852, \"res\": 1852 / 4}\n",
    "# for table in tqdm(bathy_tables):\n",
    "#     print(f\"Running {table}\")\n",
    "#     df = pdset.table_to_df(\".db/parsed.db\", table)\n",
    "\n",
    "df = populate_velocities(df)\n",
    "results, geo_map = process_particle_filter(df, config)\n",
    "print(\"Run complete! Saving results...\")\n",
    "pdset.save_dataset(\n",
    "    [results],\n",
    "    [\"test\"],\n",
    "    output_location=\".db\",\n",
    "    output_format=\"db\",\n",
    "    dataset_name=\"results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results saved! Plotting...\")\n",
    "fig, ax = plot_estimate(geo_map, results)\n",
    "fig.savefig(f\".db/plots2/estimate/test_estimate.png\")\n",
    "plt.close(fig)\n",
    "fig, ax = plot_error(results, annotations=annotations)\n",
    "fig.savefig(f\".db/plots2/errors/test_error.png\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = None\n",
    "results_tables = pdset.get_tables(\".db/results.db\")\n",
    "for table in results_tables:\n",
    "    df = pdset.table_to_df(\".db/results.db\", table)\n",
    "    run = summarize_results(df, 1852)\n",
    "    run[\"Name\"] = table\n",
    "    if summary is None:\n",
    "        summary = run  # .copy()\n",
    "    else:\n",
    "        summary = pd.concat([summary, run], ignore_index=True)\n",
    "    summary.to_csv(\".db/summary_recovery.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = None\n",
    "results_tables = pdset.get_tables(\".db/results.db\")\n",
    "for table in results_tables:\n",
    "    df = pdset.table_to_df(\".db/results.db\", table)\n",
    "    run = summarize_results(df, 452)\n",
    "    run[\"Name\"] = table\n",
    "    if summary is None:\n",
    "        summary = run  # .copy()\n",
    "    else:\n",
    "        summary = pd.concat([summary, run], ignore_index=True)\n",
    "    summary.to_csv(\".db/summary_resolution.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Post Processing\n",
    "\n",
    "Use this section to load and post process the results data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.process_dataset as pdset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.particle_filter import summarize_results\n",
    "import os\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tables = pdset.get_tables(\".db/results.db\")\n",
    "len(results_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in results_tables:\n",
    "    table_df = pdset.table_to_df(\".db/results.db\", table)\n",
    "    summary = summarize_results(table, table_df, 1852)\n",
    "    summary.to_csv(\n",
    "        \".db/plots/summary.csv\",\n",
    "        mode=\"a\",\n",
    "        header=(not os.path.exists(\".db/plots/summary.csv\")),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\n",
    "    \".db/plots/summary.csv\",\n",
    "    header=0,\n",
    "    dtype={\n",
    "        \"\": int,\n",
    "        \"name\": str,\n",
    "        \"start\": str,\n",
    "        \"stop\": str,\n",
    "        \"duration\": str,\n",
    "        \"average_error\": float,\n",
    "        \"max_error\": float,\n",
    "        \"min_error\": float,\n",
    "    },\n",
    ")\n",
    "summary[\"num\"] = summary[\"Unnamed: 0\"]\n",
    "summary = summary.drop(columns=[\"Unnamed: 0\"])\n",
    "# summary['start'] = pd.to_datetime(summary['start'], format=\"%Y-%m-%d %H:%M:%S%z\")\n",
    "# summary['end'] = pd.to_datetime(summary['end'], format=\"%Y-%m-%d %H:%M:%S%z\")\n",
    "summary[\"start\"] = pd.to_timedelta(summary[\"start\"])\n",
    "summary[\"end\"] = pd.to_timedelta(summary[\"end\"])\n",
    "summary[\"duration\"] = pd.to_timedelta(summary[\"duration\"])\n",
    "summary.head()\n",
    "\n",
    "len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery = summary.loc[summary[\"min error\"] > 452]\n",
    "len(recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if all the tables in results_tables are present in summary[\"name\"] and if not capture the missing tables\n",
    "missing = []\n",
    "for table in results_tables:\n",
    "    if table not in summary[\"name\"].values:\n",
    "        missing.append(table)\n",
    "\n",
    "total = len(results_tables)\n",
    "num_recoveries = total - len(missing)\n",
    "print(\n",
    "    f\"There are {total} total trajectories. We were able to recover at least one position fix below drift error in {num_recoveries} ({num_recoveries / total :0.4f}) trajectories.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel = summary.loc[summary[\"min error\"] <= 452]\n",
    "\n",
    "# check to see if the tables in pixel are present in summary[\"name\"] and if not capture the missing tables\n",
    "missing = []\n",
    "for table in results_tables:\n",
    "    if table not in pixel[\"name\"].values:\n",
    "        missing.append(table)\n",
    "below_pixel_fixes = total - len(missing)\n",
    "\n",
    "print(\n",
    "    f\"There are {len(pixel)} total below pixel resolution fixes. We were able to achieve at least one position estimate below drift error in {below_pixel_fixes} ({below_pixel_fixes/total :0.4f}) trajectories.\"\n",
    ")\n",
    "print(f\"mean duration: {pixel['duration'].mean()} and median duration: {pixel['duration'].median()}\")\n",
    "print(f\"mean error: {pixel['min error'].mean()} and median error: {pixel['min error'].median()}\")\n",
    "print(f\"minium duration: {pixel['duration'].min()} and maximum duration: {pixel['duration'].max()}\")\n",
    "print(f\"minimum error: {pixel['min error'].min()} and maximum error: {pixel['min error'].max()}\")\n",
    "print(f\"mean start: {pixel['start'].mean()} and median start: {pixel['start'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.sort_values(by=\"min error\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.sort_values(by=\"start\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.sort_values(by=\"duration\").tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.sort_values(by=\"average_error\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the line in summary that has the closest to the mean duration\n",
    "summary.loc[abs(summary[\"duration\"] - summary[\"duration\"].median()) <= timedelta(minutes=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"duration\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"On average we were able to recover a position fix with an mean duration of {summary['duration'].mean()}, median duration of {summary['duration'].median()} and a mean error of {summary['average_error'].mean()} and median error {summary['average_error'].median()}.\"\n",
    ")\n",
    "\n",
    "print(f\"Minimum duration {summary['duration'].min()} and maximum duration {summary['duration'].max()}.\")\n",
    "print(f\"Minimum error {summary['average_error'].min()} and maximum error {summary['average_error'].max()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = summary.loc[summary[\"num\"] == 0]\n",
    "# first.head()\n",
    "\n",
    "print(\n",
    "    f\"The first position recover occurs with a mean of {first['start'].mean()} and median {first['start'].median()} after the start of the trajectory.\"\n",
    ")\n",
    "print(\n",
    "    f\"with an mean duration of {first['duration'].mean()}, median duration of {first['duration'].median()} and a mean error of {first['average_error'].mean()} and median error {first['average_error'].median()}.\"\n",
    ")\n",
    "\n",
    "print(f\"Minimum duration {first['duration'].min()} and maximum duration {first['duration'].max()}.\")\n",
    "print(f\"Minimum error {first['average_error'].min()} and maximum error {first['average_error'].max()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gravity\n",
    "\n",
    "Recreate the above simulation and measurment model development this time with gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gmt_tool import inflate_bounds, get_map_section, get_map_point\n",
    "import src.process_dataset as pdset\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "config = json.load(open(\"config.json\", \"r\"))\n",
    "tables = pdset.get_tables(\".db/parsed.db\")\n",
    "gravity_tables = [table for table in tables if \"_G_\" in table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gravity = np.array([])\n",
    "\n",
    "for table in gravity_tables:\n",
    "    data = pdset.table_to_df(\".db/parsed.db\", table)\n",
    "    min_lon = data.LON.min()\n",
    "    max_lon = data.LON.max()\n",
    "    min_lat = data.LAT.min()\n",
    "    max_lat = data.LAT.max()\n",
    "    min_lon, min_lat, max_lon, max_lat = inflate_bounds(min_lon, min_lat, max_lon, max_lat, 0.25)\n",
    "    gravity_map = get_map_section(min_lon, max_lon, min_lat, max_lat, \"gravity\", \"01m\", \"temp\")\n",
    "    d_gravity = np.hstack([d_gravity, data[\"GRAV_ANOM\"] - get_map_point(gravity_map, data.LON, data.LAT)])\n",
    "\n",
    "config[\"gravity_mean_d\"] = np.mean(d_gravity, where=~np.isnan(d_gravity))\n",
    "config[\"gravity_std\"] = np.std(d_gravity, where=~np.isnan(d_gravity))\n",
    "\n",
    "if os.path.exists(\"config.json\"):\n",
    "    # delete the file\n",
    "    os.remove(\"config.json\")\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f)\n",
    "\n",
    "plt.hist(d_gravity, bins=100, density=True)\n",
    "plt.xlim([-50, 75])\n",
    "plt.xlabel(\"Gravity Difference (mGal)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Gravity Anomaly Difference\")\n",
    "plt.savefig(\".db/plots/gravity_diff.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnetics\n",
    "\n",
    "Recreation with magnetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gmt_tool import inflate_bounds, get_map_section, get_map_point\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "config = json.load(open(\"config.json\", \"r\"))\n",
    "tables = pdset.get_tables(\".db/parsed.db\")\n",
    "mag_tables = [table for table in tables if \"_M_\" in table]\n",
    "\n",
    "df = pdset.table_to_df(\".db/parsed.db\", mag_tables[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_magnetics = np.array([])\n",
    "\n",
    "for table in mag_tables:\n",
    "    data = pdset.table_to_df(\".db/parsed.db\", table)\n",
    "    min_lon = data.LON.min()\n",
    "    max_lon = data.LON.max()\n",
    "    min_lat = data.LAT.min()\n",
    "    max_lat = data.LAT.max()\n",
    "    min_lon, min_lat, max_lon, max_lat = inflate_bounds(min_lon, min_lat, max_lon, max_lat, 0.25)\n",
    "    mag_map = get_map_section(min_lon, max_lon, min_lat, max_lat, \"magnetic\", \"02m\", \"temp\")\n",
    "    d_magnetics = np.hstack([d_magnetics, data[\"MAG_RES\"] - get_map_point(mag_map, data.LON, data.LAT)])\n",
    "\n",
    "config[\"magnetic_mean_d\"] = np.mean(d_magnetics, where=~np.isnan(d_magnetics))\n",
    "config[\"magnetic_std\"] = np.std(d_magnetics, where=~np.isnan(d_magnetics))\n",
    "\n",
    "if os.path.exists(\"config.json\"):\n",
    "    # delete the file\n",
    "    os.remove(\"config.json\")\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d_magnetics, bins=100, density=True)\n",
    "plt.xlim([-500, 500])\n",
    "plt.xlabel(\"Magnetic Difference (nT)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Magnetic Residual Difference\")\n",
    "plt.savefig(\".db/plots/mag_diff.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"\":\n",
    "    print(\"EMPTY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = [str(i) for i in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST = \"\".join(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"A\" in \"AaBbCc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx, names = tbx.parse_trackline_from_file(\"./test/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not []:\n",
    "    print(\"EMPTY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"G\" in \"DMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"78123006.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "        \"./test/test_data.m77t\",\n",
    "        header=0,\n",
    "        index_col=0,\n",
    "        parse_dates=True,\n",
    "        dtype={\n",
    "            \"LAT\": float,\n",
    "            \"LON\": float,\n",
    "            \"CORR_DEPTH\": float,\n",
    "            \"MAG_TOT\": float,\n",
    "            \"MAG_RES\": float,\n",
    "            \"GRA_OBS\": float,\n",
    "            \"FREEAIR\": float,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"AB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_manager import m77t as tbx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tbx.read_m77t(\"./source_data/78123006.m77t\")\n",
    "data = tbx.m77t_to_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pd.io.json.build_table_schema(data)\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "def get_engine(server, database, username, password):\n",
    "    \"\"\"Creates and returns an SQLAlchemy engine for SQL Server.\"\"\"\n",
    "    connection_string = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "    engine = create_engine(connection_string)\n",
    "    return engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Table, Column, Integer, String, MetaData, select\n",
    "from sqlalchemy.dialects.mssql import NVARCHAR, FLOAT\n",
    "\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define your table schema as reflected from the database or defined by your application\n",
    "collections = Table('Collections', metadata,\n",
    "                    Column('CollectionID', Integer, primary_key=True),\n",
    "                    Column('CollectionName', NVARCHAR(255), nullable=False),\n",
    "                    Column('Description', NVARCHAR('max'))\n",
    "                    )\n",
    "\n",
    "def insert_collection(engine, collection_name, description=\"\"):\n",
    "    \"\"\"Insert a new collection using SQLAlchemy and return its CollectionID.\"\"\"\n",
    "    insert_stmt = collections.insert().values(CollectionName=collection_name, Description=description)\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(insert_stmt)\n",
    "        conn.commit()\n",
    "        collection_id = result.inserted_primary_key[0]  # Get the primary key of the inserted record\n",
    "    return collection_id\n",
    "\n",
    "def upload_data(df, collection_id, engine):\n",
    "    \"\"\"Uploads data from a DataFrame to the RawData table, linking it to the specified CollectionID.\"\"\"\n",
    "    df['CollectionID'] = collection_id  # Add CollectionID to the DataFrame\n",
    "    df.to_sql(name='RawData', con=engine, if_exists='append', index=False)\n",
    "\n",
    "def query_data_by_collection(collection_id, engine):\n",
    "    \"\"\"Queries data for a specific collection and returns it as a DataFrame.\"\"\"\n",
    "    query = f\"SELECT * FROM RawData WHERE CollectionID = {collection_id}\"\n",
    "    return pd.read_sql_query(query, con=engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine(\"localhost\", \"geonavdb\", \"sa\", \"2016SpringGardenStreet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_id = insert_collection(engine, \"test_collection\", \"This is a test collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
